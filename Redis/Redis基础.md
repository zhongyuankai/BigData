# Redis 基础

## 为什么要使用 redis

因为传统的关系型数据库如`Mysql`已经不能适用所有的场景了，比如秒杀的库存扣减，APP首页的访问流量高峰等等，都很容易把数据库打崩，所以引入了缓存中间件，目前市面上比较常用的缓存中间件有**Redis**和**Memcached**不过中和考虑了他们的优缺点，最后选择了Redis。

## redis 的五大数据类型
- **String**：最基本的数据类型，一个`key`对应一个`value`。`string`类型是二进制安全的。意思是`redis`的`string`可以包含任何数据。比如`jpg`图片或者序列化的对象。`value`最多可以是`512M`；
- **Hash（哈希）**：是一个键值对集合。
- **List（列表）**：是简单的字符串列表，按照插入顺序排序。底层是链表；
- **Set（集合）**：是`string`类型的无序集合。通过`HashTable`实现。
- **zset(sorted set：有序集合)**：`zset` 和 `set` 一样也是`string`类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个`double`类型的分数。`redis`正是通过分数来为集合中的成员进行从小到大的排序。`zset`的成员是唯一的,但分数(`score`)却可以重复。

## redis 的持久化

### RDB

在指定的时间间隔内将内存中的数据集快照写入磁盘，即Snapshot快照，恢复时将快照文件直接读入内存里。

**过程**：`Redis`会单独创建（`fork`）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。

整个过程中，主进程是不进行任何`IO`操作的，这就确保了极高的性能。

如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那`RDB`方式要比`AOF`方式更加的高效。

`Fork`的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）
数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。

`Rdb` 保存的是`dump.rdb`文件。

**触发 RDB 快照**

默认：

```
是1分钟内改了1万次，
或5分钟内改了10次，
或15分钟内改了1次。
```

命令`save`和`bgsave`:

- `Save`：`save`时只管保存，其它不管，全部阻塞；
- `bgsave`：`Redis`会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过`lastsave`命令获取最后一次成功执行快照的时间；

缺点：

- 在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改；
- Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑；

优势：

- 适合大规模的数据恢复；
- 对数据完整性和一致性要求不高；

### AOF（Append Only File）

**以日志的形式来记录每个写操作**，将`Redis`执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，`redis`启动之初会读取该文件重新构建数据，即`redis`重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

`Aof`保存的是`appendonly.aof`文件。

#### Rewrite

`AOF`采用文件追加方式，文件会越来越大为避免出现此种情况，新增了**重写机制**，当`AOF`文件的大小超过所设定的阈值时，`Redis`就会启动`AOF`文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用命令`bgrewriteaof`；

**重写原理**：

`AOF`文件持续增长而过大时，会`fork`出一条新进程来将文件重写(也是先写临时文件最后再`rename`)，
遍历新进程的内存中数据，每条记录有一条的`Set`语句。重写`aof`文件的操作，并没有读取旧的`aof`文件，
而是将整个内存中的数据库内容用命令的方式重写了一个新的`aof`文件，这点和快照有点类似；

**触发机制**：

`Redis`会记录上次重写时的`AOF`大小，默认配置是当`AOF`文件大小是上次`rewrite`后大小的一倍且文件大于`64M`时触发。

**优势**：

- 每修改同步：`appendfsync always`   同步持久化 每次发生变更会被立即记录到磁盘  性能较差但数据完整性比较好。
- 每秒同步：`appendfsync everysec`    异步操作，每秒记录   如果一秒内宕机，有数据丢失；
- 不同步：`appendfsync no`   从不同步；

**劣势**：

- 相同数据集的数据而言`aof`文件要远大于`rdb`文件，恢复速度慢于`rdb`;
- `Aof`运行效率要慢于`rdb`,每秒同步策略效率较好，不同步效率和`rdb`相同。

## Redis 的复制(Master/Slave)

即主从复制，主机数据更新后根据配置和策略，自动同步到备机的`master/slaver`机制，`Master`以写为主，`Slave`以读为主。

**作用：**读写分离、容灾恢复。

**配置**：配从(库)不配主(库)。从库配置：`slaveof` 主库`IP` 主库端口。（可以这个`info replication`命令来查看，当前机器的角色）

**常用3招**： 

- 一主二仆：`Master`以写为主，`slave`以读为主。
- 薪火相传：上一个`Slave`可以是下一个`slave`的`Master`，`Slave`同样可以接收其他`slaves`的连接和同步请求，那么该`slave`作为了链条中下一个的`master`,可以有效减轻`master`的写压力。
- 反客为主：使当前数据库停止与其他数据库的同步，转成主数据库。

#### 复制原理

1. `Slave`启动成功连接到`master`后会发送一个`sync`命令；
2. `Master`接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，`master`将传送整个数据文件到`slave`,以完成一次完全同步；
3. 全量复制：而`slave`服务在接收到数据库文件数据后，将其存盘并加载到内存中；
4. 增量复制：`Master`继续将新的所有收集到的修改命令依次传给`slave`,完成同步；
5. 但是只要是重新连接`master`，一次完全同步（全量复制) 将被自动执行；

#### 哨兵模式(sentinel)

反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。

问题：如果之前的`master`重启回来，会不会双`master`冲突？

不会的，会成为`salve`。

一组`sentinel`能同时监控多个`Master`。

#### 复制的缺点

由于所有的写操作都是先在`Master`上操作，然后同步更新到`Slave`上，所以从`Master`同步到`Slave`机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，`Slave`机器数量的增加也会使这个问题更加严重。

#### 内存淘汰机制，手写  LRU

**`Redis`**的过期策略，是有**定期删除+惰性删除**两种。

##### 定期删除

默认`100ms`就随机抽一些设置了过期时间的`key`，去检查是否过期，过期了就删了。

**为什么不扫描全部设置了过期时间的key呢？**

假如`Redis`里面所有的`key`都有过期时间，都扫描一遍？那太恐怖了，而且我们线上基本上也都是会设置一定的过期时间的。全扫描跟你去查数据库不带`where`条件不走索引全表扫描一样，`100ms`一次，`Redis`累都累死了。

##### 惰性删除

见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。

如果定期删除和惰性删除都没能将数据删除，这时就需要内存淘汰机制了。

>官网上给到的内存淘汰机制是以下几个：
>
>- **noeviction**:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
>
>- **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
>
>- **volatile-lru**: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
>
>- **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。
>
>- **volatile-random**: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
>
>- **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。
>
>  如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

手写`LRU`，其实在**`LinkedHashMap`**中实现了`LRU`算法的。当容量超过100时，开始执行**`LRU`**策略：将最近最少未使用的 对象 删除掉。

```java
// true 表示让LinkedHashMap按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。
final Map<String, String> lruMap = Collections.synchronizedMap(
        new LinkedHashMap<String, String>(3, .75F, true){
            @Override
            protected boolean removeEldestEntry(Map.Entry<String, String> eldest) {
                // 当map中的数据大于指定的缓存的个数的时候，就会自动删除最老的数据
                return size() > 100;
            }
        });
```

```java
/**
 * redis 内存淘汰策略
 * @author zhongyuankai
 * @date 2020/6/29
 */
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private Integer CACHE_SIZE;

    public LRUCache(int cacheSize) {
        this.CACHE_SIZE = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > CACHE_SIZE;
    }
}
```



## Redis 为什么那么快

**`Redis`**采用的是基于内存的采用的是单进程单线程模型的 `KV `数据库，由`C`语言编写，官方提供的数据是可以达到`100000+`的**`QPS`（每秒内查询次数）**。

- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于**`HashMap`**，**`HashMap`**的优势就是查找和操作的时间复杂度都是`O(1)`；
- 数据结构简单，对数据操作也简单，**`Redis`**中的数据结构是专门进行设计的；
- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 **`CPU`**，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 使用多路`I/O`复用模型，非阻塞`IO`；
- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，**`Redis`**直接自己构建了`VM`机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；